# ivector-compute-lda --total-covariance-factor=0.0 --dim=400 "ark:ivector-subtract-global-mean scp:exp/ivectors_swbd_train/ivector.scp ark:- |" ark:data/swbd_train/utt2spk exp/ivectors_swbd_train/transform.mat 
# Started at Sun Feb  3 14:16:48 JST 2019
#
ivector-compute-lda --total-covariance-factor=0.0 --dim=400 'ark:ivector-subtract-global-mean scp:exp/ivectors_swbd_train/ivector.scp ark:- |' ark:data/swbd_train/utt2spk exp/ivectors_swbd_train/transform.mat 
ivector-subtract-global-mean scp:exp/ivectors_swbd_train/ivector.scp ark:- 
LOG (ivector-subtract-global-mean:main():ivector-subtract-global-mean.cc:76) Read 33037 iVectors.
LOG (ivector-subtract-global-mean:main():ivector-subtract-global-mean.cc:79) Norm of iVector mean was 0.0218794
LOG (ivector-subtract-global-mean:main():ivector-subtract-global-mean.cc:108) Wrote 33037 mean-subtracted iVectors
LOG (ivector-compute-lda:main():ivector-compute-lda.cc:267) Read 33037 utterances, 0 with errors.
LOG (ivector-compute-lda:main():ivector-compute-lda.cc:273) Computing within-class covariance.
LOG (ivector-compute-lda:main():ivector-compute-lda.cc:278) 2-norm of iVector mean is 1.94445e-07
LOG (ivector-compute-lda:ComputeLdaTransform():ivector-compute-lda.cc:122) Stats have 2789 speakers, 33037 utterances. 
LOG (ivector-compute-lda:ComputeLdaTransform():ivector-compute-lda.cc:156) Singular values of between-class covariance after projecting with interpolated [total/within] covariance with a weight of 0 on the total covariance, are:  [ 13.1628 11.6888 6.71075 5.73335 5.39683 5.00208 4.46243 4.25741 3.86797 3.81177 3.7357 3.63625 3.60242 3.4563 3.39854 3.29835 3.20605 3.0958 3.05428 2.99694 2.92339 2.86319 2.83014 2.8057 2.68193 2.60483 2.60102 2.57556 2.53833 2.52371 2.48997 2.46741 2.41784 2.39175 2.36266 2.32673 2.31447 2.27672 2.23167 2.20969 2.19548 2.16592 2.14277 2.12576 2.09918 2.0615 2.04278 2.03594 2.03453 1.99586 1.96482 1.93865 1.93096 1.90089 1.8732 1.8684 1.86427 1.83856 1.82631 1.81046 1.79271 1.76172 1.75102 1.7462 1.73242 1.72191 1.71016 1.69454 1.68229 1.66748 1.66204 1.6493 1.64696 1.6299 1.61343 1.59952 1.5893 1.57931 1.57385 1.56111 1.54233 1.5372 1.53049 1.50978 1.50244 1.49045 1.48188 1.47608 1.46967 1.45634 1.45155 1.43998 1.42896 1.42102 1.40945 1.40322 1.39247 1.38555 1.37215 1.36328 1.35387 1.34166 1.33681 1.33383 1.32061 1.31578 1.31095 1.30482 1.29939 1.29347 1.28245 1.28142 1.27529 1.26495 1.26151 1.24836 1.23925 1.23512 1.22734 1.21879 1.21484 1.21354 1.20802 1.20195 1.19379 1.19344 1.18103 1.16871 1.16461 1.15761 1.15409 1.1514 1.14471 1.14291 1.1369 1.1262 1.11632 1.11366 1.11119 1.10571 1.09696 1.09449 1.08762 1.08261 1.07754 1.07606 1.073 1.06301 1.06051 1.05515 1.05044 1.0407 1.03429 1.0313 1.03036 1.02641 1.02212 1.02112 1.01175 1.00467 1.00283 0.996276 0.995001 0.988115 0.98748 0.980675 0.975623 0.971146 0.968219 0.96087 0.955077 0.949559 0.94761 0.945158 0.937359 0.93479 0.933577 0.928931 0.924401 0.920221 0.916681 0.916261 0.907056 0.901675 0.897249 0.891304 0.888063 0.886075 0.882055 0.877413 0.874196 0.870765 0.867215 0.86499 0.860359 0.857547 0.851486 0.848923 0.841229 0.839612 0.837456 0.832739 0.830993 0.826826 0.824519 0.822823 0.819724 0.815072 0.814015 0.809963 0.807423 0.805333 0.80033 0.796367 0.793131 0.788231 0.785583 0.782111 0.781366 0.77728 0.775864 0.770129 0.768862 0.764949 0.763776 0.758052 0.756713 0.754091 0.749676 0.74644 0.744293 0.740983 0.737287 0.733248 0.731927 0.730065 0.72631 0.725837 0.720895 0.719769 0.714449 0.712714 0.706769 0.702951 0.700875 0.700309 0.695736 0.694865 0.692861 0.690801 0.686806 0.684799 0.682406 0.68092 0.676014 0.669904 0.667791 0.663758 0.661343 0.659961 0.658978 0.656641 0.655404 0.651309 0.64963 0.646281 0.645936 0.642561 0.6416 0.63546 0.634034 0.632607 0.62869 0.625817 0.624284 0.622403 0.621086 0.61899 0.615378 0.611336 0.608274 0.605739 0.604217 0.601777 0.600556 0.599703 0.596745 0.592303 0.591546 0.589349 0.586691 0.584991 0.583146 0.580134 0.576303 0.575435 0.574845 0.57079 0.567104 0.564502 0.563182 0.561278 0.559887 0.554442 0.552887 0.551748 0.55037 0.54916 0.546833 0.545172 0.54359 0.542162 0.539871 0.537878 0.534341 0.530416 0.530228 0.528707 0.527192 0.525776 0.524584 0.523852 0.519145 0.516409 0.515017 0.512067 0.510467 0.510006 0.508086 0.505549 0.502324 0.500409 0.499753 0.49806 0.496908 0.495375 0.493029 0.490913 0.490802 0.48905 0.485953 0.48309 0.481872 0.47974 0.479467 0.477125 0.474624 0.471833 0.470899 0.470093 0.468977 0.467591 0.464992 0.461777 0.461093 0.458856 0.457171 0.454887 0.453787 0.451703 0.449198 0.447792 0.446629 0.444659 0.442835 0.441565 0.440414 0.438023 0.437761 0.436744 0.432372 0.431505 0.429787 0.428933 0.426937 0.424411 0.422802 0.419966 0.419516 0.418077 0.416717 0.414036 0.411799 0.410494 0.408343 0.40807 0.407308 0.405375 0.404304 0.40353 0.402683 0.400459 0.398267 0.395486 0.391441 0.390509 0.389375 0.38887 0.387934 0.385786 0.385206 0.383225 0.38121 0.380638 0.378769 0.378017 0.376096 0.374424 0.371959 0.37039 0.369808 0.367447 0.365668 0.363987 0.36117 0.360157 0.359535 0.356677 0.355878 0.355311 0.352849 0.352451 0.351551 0.35013 0.348998 0.348499 0.345211 0.34465 0.344181 0.342213 0.341523 0.339009 0.338347 0.335331 0.334425 0.333556 0.332029 0.331571 0.329809 0.326927 0.325389 0.324158 0.322339 0.32077 0.320061 0.317881 0.316935 0.31538 0.314311 0.311059 0.310866 0.309232 0.307668 0.305517 0.304656 0.303939 0.302759 0.302211 0.3008 0.299397 0.298242 0.297019 0.29617 0.294604 0.292652 0.292216 0.28973 0.289062 0.287744 0.286771 0.285018 0.282292 0.281542 0.280517 0.279822 0.278171 0.277895 0.277202 0.274293 0.273466 0.272077 0.270494 0.270216 0.269867 0.268153 0.267245 0.265855 0.265131 0.262407 0.261136 0.260252 0.259681 0.258767 0.256458 0.254625 0.253919 0.253109 0.251734 0.25066 0.248905 0.248123 0.247183 0.246056 0.244973 0.24332 0.242718 0.239128 0.238471 0.238138 0.237014 0.234904 0.233878 0.233336 0.232017 0.230699 0.229466 0.228896 0.228622 0.226276 0.225227 0.224011 0.223224 0.221059 0.220734 0.219121 0.217044 0.216568 0.215256 0.213833 0.212791 0.211797 0.210938 0.210035 0.208816 0.207104 0.206843 0.205767 0.205574 0.202945 0.202426 0.199288 0.198692 0.198026 0.196969 0.194845 0.194246 0.193531 0.192017 0.191455 0.190203 0.188689 0.187718 0.185597 0.183777 0.182347 0.181918 0.181231 0.180638 0.178927 0.177437 0.176581 0.176348 0.174718 0.174106 0.173026 0.172013 0.169631 0.167776 0.166151 0.165864 0.163893 0.163065 0.161905 0.161021 0.158785 0.15781 0.156515 0.155837 0.153991 0.153583 0.15219 0.149031 0.148409 0.147939 0.147123 0.144595 0.143612 0.142241 0.139641 0.138944 0.137956 0.135357 0.13369 0.128832 0.127567 0.12675 0.123169 0.121656 0.115223 0.112782 ]
LOG (ivector-compute-lda:main():ivector-compute-lda.cc:296) Wrote LDA transform to exp/ivectors_swbd_train/transform.mat
# Accounting: time=8 threads=1
# Ended (code 0) at Sun Feb  3 14:16:56 JST 2019, elapsed time 8 seconds
